{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patryk Laskowski\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions to answer\n",
    "\n",
    "#### I. Display OFF vs ON (No Tensorflow)\n",
    "- Is displaying the results in real time coputionally expensive?\n",
    "- If so, is it might be optimized?\n",
    "\n",
    "#### II. Tensorflow ON/OFF (actually computing the results)\n",
    "- How CPU consuming is to run TF model?\n",
    "- What is the FPS rate when TF is making predictions? Is there any change in FPS rate?\n",
    "- How about number of threads? Does it increase?\n",
    "- Is it any helpful to not display the results at all when output is 10% of oryginal?\n",
    "\n",
    "#### III. Multiprocessing solution\n",
    "- Does multiprocessing (when each computation is assigned to single separate process) helps in runtime?\n",
    "- When number of processes increase linearly does the CPU consumption increase linearly as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer parameters:\n",
    "---\n",
    "\n",
    "### Overwiew:\n",
    "\n",
    "<p><img width=\"500\" src=\"./images/overview.png\"></p>\n",
    "<br>\n",
    "\n",
    "\n",
    "### Displays:\n",
    "\n",
    "<p align=\"left\"><img width=\"500\" src=\"./images/displays.png\"></p>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Python process CPU consumption as well as number of threads command\n",
    "\n",
    "```bash\n",
    "top -stats pid,command,cpu,th,ppid -n 5 | grep -e Python\n",
    "```\n",
    "\n",
    "<p align=\"left\"><img width=\"700\" src=\"./images/terminal_top_python.png\"></p>\n",
    "\n",
    "\n",
    "### Example app output\n",
    "\n",
    "```bash\n",
    "python test.py\n",
    "```\n",
    "\n",
    "<p align=\"left\"><img width=\"850\" src=\"./images/terminal_python.png\"></p>\n",
    "\n",
    "### Activity Monitor (CPU usage)\n",
    "\n",
    "Each CPU consumption (16 logical CPUs total, 8 physical CPUs)\n",
    "\n",
    "<p align=\"left\"><img width=\"850\" src=\"./images/cpu_usage.png\"></p>\n",
    "\n",
    "### Others:\n",
    "- [x] Python 3.7.9\n",
    "- [x] tensorflow==2.3.1\n",
    "- [x] opencv-python-headless==4.4.0.46\n",
    "- [x] YOLOv4 model with oryginal COCO dataset weights (80 classes), converted to TF Lite model.\n",
    "\n",
    "<p align=\"left\"><img width=\"600\" src=\"./images/software.png\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Display OFF vs ON (No Tensorflow)\n",
    "---\n",
    "\n",
    "#### Notes\n",
    "- Number of threads is high because tensorflow is ready to use in background. Without Tensorflow initialized #TH is about 19.\n",
    "\n",
    "#### Questions\n",
    "- [ ] **Is displaying the results in real time coputionally expensive?**\n",
    "- [ ] **If so, is it might be optimized?**\n",
    "\n",
    "---\n",
    "\n",
    "### 1) Oryginal resolution (720, 1280, 3)\n",
    "\n",
    "#### DISPLAY OFF\n",
    "- image shape: (720, 1280, 3) (oryginal)\n",
    "- display    : OFF\n",
    "- Tensorflow : OFF\n",
    "- grayscale  : OFF\n",
    "\n",
    "```bash\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 100.0%; Max_fps: 30; Shape: (720, 1280, 3); \n",
    "\n",
    "                 RAM%  #TH\n",
    "Python           18.5  71   \n",
    "```\n",
    "\n",
    "#### DISPLAY ON\n",
    "- image shape: (720, 1280, 3) (oryginal)\n",
    "- display    : ON\n",
    "- Tensorflow : OFF\n",
    "- grayscale  : OFF\n",
    "\n",
    "```bash\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 100.0%; Max_fps: 30; Shape: (720, 1280, 3); \n",
    "\n",
    "                 RAM%  #TH\n",
    "Python           78.3  71   \n",
    "```\n",
    "\n",
    "#### Summary\n",
    "Resolution matters. Using oryginal image size there is a big difference between display ON and OFF.\n",
    "\n",
    "$$ \\Delta = 78.3 - 18.5 = 59.8 $$\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "### 2) Scaled resolution (72, 128, 3)\n",
    "\n",
    "#### DISPLAY OFF\n",
    "- image shape: (72, 128, 3) (10x smaller)\n",
    "- display    : OFF\n",
    "- Tensorflow : OFF\n",
    "- grayscale  : OFF\n",
    "\n",
    "```bash\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 10.0%; Max_fps: 30; Shape: (72, 128, 3); \n",
    "\n",
    "                 RAM%  #TH\n",
    "Python           16.5  70 \n",
    "```\n",
    "\n",
    "#### DISPLAY ON\n",
    "- image shape: (72, 128, 3) (10x smaller)\n",
    "- display    : ON\n",
    "- Tensorflow : OFF\n",
    "- grayscale  : OFF\n",
    "\n",
    "```bash\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 10.0%; Max_fps: 30; Shape: (72, 128, 3); \n",
    "\n",
    "                 RAM%  #TH\n",
    "Python           18.4  71   \n",
    "```\n",
    "\n",
    "#### Summary\n",
    "However the difference is not that big when photo is **10x smaller** ((720, 1280, 3) -> (72, 128, 3)).\n",
    "\n",
    "$$ \\Delta = 18.4 - 16.5 = 1.9 $$\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### Answers:\n",
    "- [x] **Is displaying the results in real time coputionally expensive?**\n",
    "    - Yes it is, but only when the image size is significant.\n",
    "- [x] **If so, is it might be optimized?**\n",
    "    - Reduce the image size when display.\n",
    "\n",
    "---\n",
    "\n",
    "- Does the client really have need to see the output in real time? That might couse problems... **Main objective is to create software to retreive information from input**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Tensorflow ON/OFF (actually computing the results)\n",
    "---\n",
    "\n",
    "#### Notes\n",
    "\n",
    "- Tensorflow model has strict input - model always resize the input. This one requires (1, 416, 416, 3) input size.\n",
    "- YOLOv4 model architecture.\n",
    "- COCO dataset default weights.\n",
    "<br>\n",
    "\n",
    "Lowest parameters od displaying are set (accuracy of model doesn't matter):\n",
    "- scale is 10% of oryginal (lower than expected by model - model will upsize)\n",
    "- grayscale on (2D image) (lower than expected by model - model will convert to RGB)\n",
    "- 30 FPS maximum (default)\n",
    "<br>\n",
    "\n",
    "#### Questions\n",
    "- [ ] **How CPU consuming is to run TF model?**\n",
    "- [ ] **What is the FPS rate when TF is making predictions? Is there any change in FPS rate?**\n",
    "- [ ] **How about number of threads? Does it increase?**\n",
    "- [ ] **Is it any helpful to not display the results at all when output is 10% of oryginal?**\n",
    "\n",
    "---\n",
    "\n",
    "### 1) Tensorflow OFF\n",
    "\n",
    "#### Display OFF\n",
    "\n",
    "- image shape: (72, 128) (10x smaller)\n",
    "- display    : OFF\n",
    "- Tensorflow : OFF\n",
    "- grayscale  : ON\n",
    "\n",
    "```bash\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 10.0%; Max_fps: 30; Shape: (72, 128);     1.04 s (benchmark: 1 s.)\n",
    "\n",
    "                 RAM%     #TH\n",
    "Python           17.1     70\n",
    "```\n",
    "\n",
    "#### Display ON\n",
    "\n",
    "- image shape: (72, 128) (10x smaller)\n",
    "- display    : ON\n",
    "- Tensorflow : OFF\n",
    "- grayscale  : ON\n",
    "\n",
    "```bash\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 10.0%; Max_fps: 30; Shape: (72, 128);     1.02 s (benchmark: 1 s.)\n",
    "\n",
    "                 RAM%     #TH\n",
    "Python           19.9     69 \n",
    "```\n",
    "\n",
    "### 2) Tensorflow ON\n",
    "\n",
    "Note that when Tensorflow model is ON, the output value has 3 channels (., ., 3). This is determined by the tensorflow model expected input. The function resizes model input to fit its needs.<br>\n",
    "\n",
    "#### Display OFF\n",
    "\n",
    "- image shape: (72, 128) (10x smaller)\n",
    "- display    : OFF\n",
    "- Tensorflow : ON\n",
    "- grayscale  : ON\n",
    "\n",
    "```bash\n",
    "FPS_main: 2; FPS_sub: 2; Scale: 10.0%; Max_fps: 30; Shape: (72, 128, 3);     1.86 s (benchmark: 1 s.)\n",
    "\n",
    "                 RAM%      #TH\n",
    "Python           204.6     73/1\n",
    "```\n",
    "\n",
    "#### Display ON\n",
    "\n",
    "- image shape: (72, 128) (10x smaller)\n",
    "- display    : ON\n",
    "- Tensorflow : ON\n",
    "- grayscale  : ON\n",
    "\n",
    "```bash\n",
    "FPS_main: 2; FPS_sub: 2; Scale: 10.0%; Max_fps: 30; Shape: (72, 128, 3);     1.90 s (benchmark: 1 s.)\n",
    "\n",
    "                 RAM%      #TH\n",
    "Python           202.0     73/1\n",
    "```\n",
    "\n",
    "---\n",
    "##### Summary\n",
    "\n",
    "In both cases FPS plummet 15 times (from 30 FPS to 2 FPS (while max_fps=30)).\n",
    "Also the argument standing for GIL problem (i.e. multiple threads connot run simoultanesly inside single process) is visible when compare the last value of seconds. **I suspect that this value is trying to be scored paralelly to tensorflow model which is super CPU consuming and not let the counting thread to run (becouse of GIL).** Moreover it's importantthat to remember that this not imply the number of core in use. Single thread may occupy multiple cores. \n",
    "\n",
    "1) Change in CPU consumption with display ON, and Tensorflow model OFF and ON\n",
    "\n",
    "$$ \\Delta = 202 - 19.9 = 182.1 $$\n",
    "\n",
    "2) CPU delta between Tensorflow model OFF and ON when display is OFF.\n",
    "\n",
    "$$ \\Delta = 204 - 17.1 = 186.9 $$\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "##### Docs:\n",
    "- [Thread](https://docs.python.org/3/library/threading.html#threading.Thread)<br>\n",
    "- [GIL](https://docs.python.org/3/glossary.html#term-global-interpreter-lock)<br>\n",
    "\n",
    "<br>\n",
    "<p align=\"left\"><img width=\"800\" src=\"./images/gil_problem.png\"></p>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "#### Answers\n",
    "- [x] **How CPU intensive is to run TF model?**\n",
    "    - It is very CPU intensive. It is about 10x more CPU consuming than not performing analysis.\n",
    "    - TF OFF: ~20%  CPU;\n",
    "    - TF ON : ~200% CPU;\n",
    "- [x] **What is the FPS rate when TF is making predictions? Is there any change in FPS rate?**\n",
    "    - When TF is ON FPS rate drops a lot, from 30 FPS down to 2 FPS.\n",
    "- [x] **How about number of threads? Does it increase?**\n",
    "    - Number of threads increse slighly by about 3 or 4 threads (from ~69 to ~73).\n",
    "- [x] **Is it any helpful to not display the results at all when output is 10% of oryginal?**\n",
    "    - When output is small there is not significant change in both #TH and %CPU when display is ON and OFF.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Multiprocessing solution\n",
    "---\n",
    "\n",
    "See what happen when run same execution multiple times using **multiprocessing**.<br>\n",
    "This voids the GIL problem.<br>\n",
    "\n",
    "#### Questions\n",
    "- [ ] **Does multiprocessing (when each computation is assigned to single separate process) helps in runtime?**\n",
    "- [ ] **When number of processes increase linearly does the CPU consumption increase linearly as well?**\n",
    "\n",
    "---\n",
    "\n",
    "#### 1) Default - without display\n",
    "\n",
    "- n processes: 1\n",
    "- image shape: (720, 1280, 3) (oryginal)\n",
    "- display    : OFF\n",
    "- Tensorflow : OFF\n",
    "- grayscale  : OFF\n",
    "\n",
    "```bash\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 100.0%; Max_fps: 30; Shape: (720, 1280, 3); PID: 55116;    1.02 s (benchmark: 1 s.)\n",
    "\n",
    "PID.   COMMAND.         CPU%. #TH.   PPID\n",
    "55116  Python           23.3  70     55114\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Increase number of processes (ceteris paribus)\n",
    "\n",
    "#### 2) Two default processes\n",
    "\n",
    "- n processes: 2\n",
    "- image shape: (720, 1280, 3) (oryginal)\n",
    "- display    : OFF\n",
    "- Tensorflow : OFF\n",
    "- grayscale  : OFF\n",
    "\n",
    "```bash\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 100.0%; Max_fps: 30; Shape: (720, 1280, 3); PID: 55184;    1.00 s (benchmark: 1 s.)\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 100.0%; Max_fps: 30; Shape: (720, 1280, 3); PID: 55185;    1.01 s (benchmark: 1 s.)\n",
    "\n",
    "PID.   COMMAND.         CPU%. #TH.   PPID\n",
    "55184  Python           32.5  69     55181\n",
    "55185  Python           28.4  70     55181\n",
    "```\n",
    "\n",
    "#### 3) Three default processes\n",
    "\n",
    "- n processes: 3\n",
    "- image shape: (720, 1280, 3) (oryginal)\n",
    "- display    : OFF\n",
    "- Tensorflow : OFF\n",
    "- grayscale  : OFF\n",
    "\n",
    "```bash\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 100.0%; Max_fps: 30; Shape: (720, 1280, 3); PID: 55287;    1.03 s (benchmark: 1 s.)\n",
    "FPS_main: 29; FPS_sub: 29; Scale: 100.0%; Max_fps: 30; Shape: (720, 1280, 3); PID: 55288;    1.03 s (benchmark: 1 s.)\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 100.0%; Max_fps: 30; Shape: (720, 1280, 3); PID: 55289;    1.01 s (benchmark: 1 s.)\n",
    "\n",
    "PID.   COMMAND.         CPU%. #TH.   PPID\n",
    "55287  Python           35.7  69     55282\n",
    "55288  Python           28.8  69/1   55282\n",
    "55289  Python           38.8  69/1   55282\n",
    "```\n",
    "\n",
    "##### Summary\n",
    "No significant difference. Python runs three separate processes (3 different Python interpreters).<br>\n",
    "**CPU per process stays about still (~30% CPU/process). The program is running trully in parallel.**<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Turn ON the display (ceteris paribus)\n",
    "\n",
    "#### 4) Three processes, all with display ON\n",
    "\n",
    "- n processes: 3\n",
    "- image shape: (720, 1280, 3) (oryginal)\n",
    "- display    : ON\n",
    "- Tensorflow : OFF\n",
    "- grayscale  : OFF\n",
    "\n",
    "```bash\n",
    "FPS_main: 25; FPS_sub: 25; Scale: 100.0%; Max_fps: 30; Shape: (720, 1280, 3); PID: 55287;    1.05 s (benchmark: 1 s.)\n",
    "FPS_main: 24; FPS_sub: 24; Scale: 100.0%; Max_fps: 30; Shape: (720, 1280, 3); PID: 55288;    1.03 s (benchmark: 1 s.)\n",
    "FPS_main: 27; FPS_sub: 27; Scale: 100.0%; Max_fps: 30; Shape: (720, 1280, 3); PID: 55289;    1.01 s (benchmark: 1 s.)\n",
    "\n",
    "PID.   COMMAND.         CPU%. #TH.   PPID\n",
    "55287  Python           70.8  70     55282\n",
    "55288  Python           81.3  70     55282\n",
    "55289  Python           80.2  70/1   55282\n",
    "```\n",
    "\n",
    "##### Summary\n",
    "Significant (about 50 percentage points) increase of CPU usage  (now ~80% CPU/process).<br>\n",
    "Image is still processed in oryginal shape.<br>\n",
    "Number of threads per process increased by 1.<br>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"text-align:center;\" >3 processes running in parallel. Display ON, Tenforflow OFF.</h3>\n",
    "<p align=\"left\"><img width=\"800\" src=\"./images/3_processes_tf_off.png\"></p>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Decrease image size (ceteris paribus)\n",
    "#### 5) Three processes, all with display ON, image shape 10x smaller (72, 128, 3)\n",
    "\n",
    "- n processes: 3\n",
    "- image shape: (72, 128, 3)\n",
    "- display    : ON\n",
    "- Tensorflow : OFF\n",
    "- grayscale  : OFF\n",
    "\n",
    "```bash\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 10.0%; Max_fps: 30; Shape: (72, 128, 3); PID: 55287;    1.04 s (benchmark: 1 s.)\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 10.0%; Max_fps: 30; Shape: (72, 128, 3); PID: 55289;    1.00 s (benchmark: 1 s.)\n",
    "FPS_main: 29; FPS_sub: 29; Scale: 10.0%; Max_fps: 30; Shape: (72, 128, 3); PID: 55288;    1.00 s (benchmark: 1 s.)\n",
    "\n",
    "PID.   COMMAND.         CPU%.     #TH.   PPID\n",
    "55287  Python           36.6      70     55282\n",
    "55288  Python           37.5      69     55282\n",
    "55289  Python           36.7      70     55282\n",
    "\n",
    "```\n",
    "\n",
    "##### Summary\n",
    "CPU usage per process decreased by about 40 percentage points, to the value when the display was OFF.<br>\n",
    "Number of threads is likely to decrease.<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Turn grayscale ON (ceteris paribus)\n",
    "#### 6) Three processes, all with display ON, image shape 10x smaller, grayscale ON (72, 128)\n",
    "\n",
    "- n processes: 3\n",
    "- image shape: (72, 128)\n",
    "- display    : ON\n",
    "- Tensorflow : OFF\n",
    "- grayscale  : ON\n",
    "\n",
    "```bash\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 10.0%; Max_fps: 30; Shape: (72, 128); PID: 55287;    1.02 s (benchmark: 1 s.)\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 10.0%; Max_fps: 30; Shape: (72, 128); PID: 55288;    1.03 s (benchmark: 1 s.)\n",
    "FPS_main: 30; FPS_sub: 30; Scale: 10.0%; Max_fps: 30; Shape: (72, 128); PID: 55289;    1.00 s (benchmark: 1 s.)\n",
    "\n",
    "\n",
    "PID.   COMMAND.         CPU%.     #TH.   PPID\n",
    "55287  Python           33.3      70     55282\n",
    "55288  Python           26.3      70     55282\n",
    "55289  Python           33.0      70     55282\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Turn Tensorflow ON (ceteris paribus)\n",
    "#### 6) Three processes, all with display ON, image shape 10x smaller, grayscale ON (72, 128), Tensorflow ON\n",
    "\n",
    "- n processes: 3\n",
    "- image shape: (72, 128)\n",
    "- display    : ON\n",
    "- Tensorflow : ON\n",
    "- grayscale  : ON\n",
    "\n",
    "```bash\n",
    "FPS_main: 1; FPS_sub: 1; Scale: 10.0%; Max_fps: 30; Shape: (72, 128, 3); PID: 55287;    1.15 s (benchmark: 1 s.)\n",
    "FPS_main: 1; FPS_sub: 1; Scale: 10.0%; Max_fps: 30; Shape: (72, 128, 3); PID: 55288;    1.27 s (benchmark: 1 s.)\n",
    "FPS_main: 1; FPS_sub: 1; Scale: 10.0%; Max_fps: 30; Shape: (72, 128, 3); PID: 55289;    1.31 s (benchmark: 1 s.)\n",
    "\n",
    "PID.   COMMAND.         CPU%.     #TH.   PPID\n",
    "55287  Python           215.6     73/1   55282\n",
    "55288  Python           205.6     73/4   55282\n",
    "55289  Python           196.4     73/4   55282\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"text-align:center;\" >3 processes running in parallel. Display ON, Tenforflow ON.</h3>\n",
    "<p align=\"left\"><img width=\"800\" src=\"./images/3_processes_tf_on.png\"></p>\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Back to default settings per process (TF still ON)\n",
    "\n",
    "See the difference of running and not running TF on 3 processes (compare to default from no.1)\n",
    "\n",
    "#### 7) Three processes, Tensorflow ON\n",
    "\n",
    "- n processes: 3\n",
    "- image shape: (720, 1280, 3) (oryginal)\n",
    "- display    : OFF\n",
    "- Tensorflow : ON\n",
    "- grayscale  : OFF\n",
    "\n",
    "```bash\n",
    "FPS_main: 1; FPS_sub: 1; Scale: 100.0%; Max_fps: 30; Shape: (720, 1280, 3); PID: 58542;    1.17 s (benchmark: 1 s.)\n",
    "FPS_main: 1; FPS_sub: 1; Scale: 100.0%; Max_fps: 30; Shape: (720, 1280, 3); PID: 58543;    1.17 s (benchmark: 1 s.)\n",
    "FPS_main: 1; FPS_sub: 1; Scale: 100.0%; Max_fps: 30; Shape: (720, 1280, 3); PID: 58544;    1.20 s (benchmark: 1 s.)\n",
    "\n",
    "PID.   COMMAND.         CPU%.     #TH.   PPID\n",
    "58542  Python           245.5     74/4   58539\n",
    "58543  Python           228.5     73/1   58539\n",
    "58544  Python           161.2     73/1   58539\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Decrease the number of processes  (default settings but TF still ON)\n",
    "\n",
    "#### 8) One process, Tensorflow ON\n",
    "\n",
    "- n processes: 1\n",
    "- image shape: (720, 1280, 3) (oryginal)\n",
    "- display    : OFF\n",
    "- Tensorflow : ON\n",
    "- grayscale  : OFF\n",
    "\n",
    "```bash\n",
    "FPS_main: 2; FPS_sub: 2; Scale: 100.0%; Max_fps: 30; Shape: (720, 1280, 3); PID: 58136;    1.01 s (benchmark: 1 s.)\n",
    "\n",
    "PID.   COMMAND.         CPU%.     #TH.   PPID\n",
    "58136  Python           213.6     74/4   58135\n",
    "```\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Answers\n",
    "- [x] **Does multiprocessing (when each computation is assigned to single separate process) helps in runtime?**\n",
    "    - Each process has its own Python interpreter running. In that case the work is split betqeen different separate environments that aren't interrupting each other as much as they would when running as a single process.\n",
    "\n",
    "<h3 style=\"text-align:center;\" >3 interpreters running in parallel fired from single Python piece.</h3>\n",
    "<p align=\"left\"><img width=\"200\" src=\"./images/3_python_interpreters.png\"></p>\n",
    "<br>\n",
    "\n",
    "- [x] **When number of processes increase linearly does the CPU consumption increase linearly as well?**\n",
    "    - Yes, the increase is about linear. Each process runs separately and as far as there is enough free resources, the consumption will be split without conflicts. But the thing is that so far 2FPS is max with TF ON (single proc.) with multiple processes this decrease to 1 FPS.\n",
    "        - Multiprocessing with single process and **TF OFF** costs about 23%CPU and 70 threads. Multiprocessing with three processes cost about 30% CPU and 69 threads each (per process).\n",
    "        - Multiprocessing with single process and **TF ON** costs about 213%CPU and 74 threads. Multiprocessing with three processes cost about 210% CPU and 73 threads each (per process).\n",
    "\n",
    "---\n",
    "\n",
    "- 1 or 2 FPS is not that bad. Why would you need higher speed than that. Of course this might be optimized by decreasing shape on model training and compiling stage.\n",
    "- The other way to increase computation speed is to use GPU!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limits and why multiprocessing is a good idea.\n",
    "---\n",
    "\n",
    "- 10 processes run, all with Tensorflow ON. \n",
    "- This is RAW function running, which means that only processes required to run TF model are used (no OpenCv trackbars, only processing that is needed to run model predictions.\n",
    "- The FPS rate is about 1 (or even less) per second.\n",
    "- Now CPU is used to its limits using multiprocessing.<br>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 style=\"text-align:center;\" >Reaching the limits.<br>10 parallel python processes running RAW Tensorflow Lite model and displaying.</h3>\n",
    "<p align=\"left\"><img width=\"900\" src=\"./images/processes_10_raw.png\"></p>\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Further research questions:\n",
    "- Socket server (indepoendent process) with model running that expect image as input and returns prediction. However this would increase network traffic.\n",
    "- Does model `.weights ` file has the same size for each model with exactly same architecture (YOLOv4)?\n",
    "- Maybe saving the results is the good solution? After all seeing the output in real time is not the goal... <u>Main objective is to predict the output based on given input. The whole GUI thing just interrupts Python running TF predictions.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Patryk Laskowski"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Computer_Vision_Kernel",
   "language": "python",
   "name": "computer_vision_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
